# Rename this file to .env after configuration
# LLM Configuration
# -----------------
# Choose your LLM backend: "ollama" or "openai"
LLM_BACKEND=ollama

# Ollama Configuration (local)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=ministral-3:3b

# OpenAI Configuration (cloud fallback)
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4o-mini

# Server Configuration
# --------------------
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Diagnostic Configuration
# ------------------------
# Timeout for network commands (seconds)
COMMAND_TIMEOUT=10

# Default DNS servers for testing
DNS_SERVERS=8.8.8.8,1.1.1.1

# Default hosts for DNS resolution tests
DNS_TEST_HOSTS=google.com,cloudflare.com

